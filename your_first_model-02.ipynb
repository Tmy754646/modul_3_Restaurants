{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка Pandas и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код по очистке данных и генерации новых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект модуля 3. О вкусной и здоровой пище\n",
    "\n",
    "## Цель: Построить модель, предсказывающую рейтинг ресторана\n",
    "\n",
    "## План\n",
    "1. Проанализировать данные, определить направления их улучшения\n",
    "2. Обработать пропуски, выбросы, придумать дополнительные признаки\n",
    "3. Разбить датасет на тренриовочную и боевые части\n",
    "4. Обучить и валидировать модель\n",
    "\n",
    "## Исходные данные\n",
    "- Restaurant_id — идентификационный номер ресторана / сети ресторанов;\n",
    "- City — город, в котором находится ресторан;\n",
    "- Cuisine Style — кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане;\n",
    "- Ranking — место, которое занимает данный ресторан среди всех ресторанов своего города;\n",
    "- Rating — рейтинг ресторана по данным TripAdvisor (именно это значение должна будет предсказывать модель);\n",
    "- Price Range — диапазон цен в ресторане;\n",
    "- Number of Reviews — количество отзывов о ресторане;\n",
    "- Reviews — данные о двух отзывах, которые отображаются на сайте ресторана;\n",
    "- URL_TA — URL страницы ресторана на TripAdvosor;\n",
    "- ID_TA — идентификатор ресторана в базе данных TripAdvisor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотека служебных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для создания словарей из слов, использованных в отзывах (для последующего ранжирования отзывов)\n",
    "def make_dict(df,col):\n",
    "    collection = {}\n",
    "    for string in df[col]:\n",
    "        for word in string:\n",
    "            if word in collection.keys():\n",
    "                collection[word]+=1\n",
    "            else:\n",
    "                collection[word] =1\n",
    "    return collection\n",
    "\n",
    "df=pd.read_csv('main_task.csv')\n",
    "df['Reviews']=df['Reviews'].apply(lambda x: x.lower())\n",
    "pattern = re.compile('[a-z]*')\n",
    "df['new'] = df['Reviews'].apply(pattern.findall)\n",
    "words = pd.Series(make_dict(df,'new')).drop('').sort_values(ascending=False)\n",
    "# Из полученного словаря берем 1000 наиболее употребимых слов и создаенм два списка: positive и negative.\n",
    "# Списки сохраняем в txt файлы: Negative_reviews.txt и Positive_reviews.txt\n",
    "\n",
    "# После того, как забрали слова - убираем поле new\n",
    "df.drop(columns=['new'], inplace=True)\n",
    "\n",
    "# Функция file_read cчитывает слова с негативной и позитивной окраской из файлов Negative_reviews.txt и Positive_reviews.txt\n",
    "def file_read(file_name):\n",
    "    import csv\n",
    "    with open(file_name) as File:\n",
    "        reader = csv.reader(File)\n",
    "        for line in reader:\n",
    "            words = line\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция marking считывает в соответствующие списики словари \"хороших\" и \"плохих\" оценок, \n",
    "# затем проверяет каждый элемент полученной в качестве параметра серии и формирует соответствующую оценку (1 или -1)\n",
    "# в поля negative и positive.\n",
    "# Затем формируется итоговое значение как сумма значений по полям positive и negative. \n",
    "\n",
    "\n",
    "def check_words(rev,words,mark):\n",
    "    for w in words:\n",
    "        df.loc[(df[rev].str.contains(w)) & ~(df[rev].str.contains('not')), 'negative'] = mark\n",
    "        df.loc[(df[rev].str.contains(w)) &  (df[rev].str.contains('not')), 'positive'] = -mark\n",
    "    return 0\n",
    "\n",
    "\n",
    "def marking (rev,mark):\n",
    "    negative = file_read('Negative_reviews.txt')\n",
    "    positive = file_read('Positive_reviews.txt')\n",
    "    df['positive'] = df['negative'] = 0\n",
    "\n",
    "    check_words(rev,negative,-1)\n",
    "    check_words(rev,positive, 1)\n",
    "    \n",
    "    df[mark]=df['positive']+df['negative']\n",
    "    df.drop(columns = ['positive','negative'], inplace=True)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def simple_list(string):\n",
    "    string = string.lower()\n",
    "    str_list = [i.strip(\"'[]\") for i in string.split(', ')]\n",
    "    return str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для обработки поля 'Cuisine Style'\n",
    "def list_to_columns(df, col, not_a_list=False):\n",
    "    if not_a_list:\n",
    "        collection = df[col].unique()\n",
    "    else:\n",
    "        collection = make_collection(df,col)\n",
    "    for i in collection:\n",
    "        df[i] = df[col].apply(lambda x: 1 if (i in x) or (i=='other') else 0)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def make_collection(df, col, not_a_list=False):\n",
    "    collection = {}\n",
    "    for i in df[col]:\n",
    "        for j in i:\n",
    "            if j in collection.keys():\n",
    "                collection[j]+=1\n",
    "            else:\n",
    "                collection[j] =1\n",
    "    collection = pd.Series(collection).sort_values(ascending=False).head(30).index.tolist()\n",
    "    collection.append('other')\n",
    "    return collection\n",
    "\n",
    "\n",
    "def make_cuis_list (city, Cities, pos):\n",
    "    cuislist=[]\n",
    "    for cuis in Cities.columns[pos:]:\n",
    "        if Cities.loc[city.name,cuis] != 0:\n",
    "            cuislist.append(cuis)\n",
    "    return cuislist\n",
    "\n",
    "\n",
    "def make_pop_cuis (city, Cities, pos):\n",
    "    result = list(Cities.loc[city.name, Cities.columns[pos:]].sort_values(ascending=False).head(city.cuis_per_rest).index)\n",
    "    return result\n",
    "\n",
    "\n",
    "def isnan(x):\n",
    "    if x!=x: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Первый взгляд на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Restaurant_id      40000 non-null  object \n",
      " 1   City               40000 non-null  object \n",
      " 2   Cuisine Style      30717 non-null  object \n",
      " 3   Ranking            40000 non-null  float64\n",
      " 4   Rating             40000 non-null  float64\n",
      " 5   Price Range        26114 non-null  object \n",
      " 6   Number of Reviews  37457 non-null  float64\n",
      " 7   Reviews            40000 non-null  object \n",
      " 8   URL_TA             40000 non-null  object \n",
      " 9   ID_TA              40000 non-null  object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>id_500</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>[['Good fast-food coffee', 'Lovely'], ['12/16/...</td>\n",
       "      <td>/Restaurant_Review-g189852-d9567331-Reviews-Es...</td>\n",
       "      <td>d9567331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35495</th>\n",
       "      <td>id_2336</td>\n",
       "      <td>Munich</td>\n",
       "      <td>['Italian', 'Mediterranean']</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>25.0</td>\n",
       "      <td>[['Dinner at Trattoria del Centro', 'Fantastic...</td>\n",
       "      <td>/Restaurant_Review-g187309-d8552181-Reviews-Tr...</td>\n",
       "      <td>d8552181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14563</th>\n",
       "      <td>id_2460</td>\n",
       "      <td>London</td>\n",
       "      <td>['Mexican', 'Polish', 'European', 'Eastern Eur...</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>207.0</td>\n",
       "      <td>[['Great find', 'Shouldnt work but definitely ...</td>\n",
       "      <td>/Restaurant_Review-g186338-d700008-Reviews-L_A...</td>\n",
       "      <td>d700008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24507</th>\n",
       "      <td>id_2423</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g190454-d10803127-Reviews-3...</td>\n",
       "      <td>d10803127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28152</th>\n",
       "      <td>id_1088</td>\n",
       "      <td>Lisbon</td>\n",
       "      <td>['Mediterranean', 'European', 'Portuguese']</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>99.0</td>\n",
       "      <td>[['See food', 'Evening meal'], ['08/24/2017', ...</td>\n",
       "      <td>/Restaurant_Review-g189158-d3574434-Reviews-Re...</td>\n",
       "      <td>d3574434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Restaurant_id       City                                      Cuisine Style  Ranking  Rating Price Range  Number of Reviews                                            Reviews                                             URL_TA      ID_TA\n",
       "6561         id_500  Stockholm                                                NaN    501.0     4.5         NaN               27.0  [['Good fast-food coffee', 'Lovely'], ['12/16/...  /Restaurant_Review-g189852-d9567331-Reviews-Es...   d9567331\n",
       "35495       id_2336     Munich                       ['Italian', 'Mediterranean']   2352.0     3.5    $$ - $$$               25.0  [['Dinner at Trattoria del Centro', 'Fantastic...  /Restaurant_Review-g187309-d8552181-Reviews-Tr...   d8552181\n",
       "14563       id_2460     London  ['Mexican', 'Polish', 'European', 'Eastern Eur...   2465.0     4.0    $$ - $$$              207.0  [['Great find', 'Shouldnt work but definitely ...  /Restaurant_Review-g186338-d700008-Reviews-L_A...    d700008\n",
       "24507       id_2423     Vienna                                                NaN   2425.0     4.0         NaN                3.0                                           [[], []]  /Restaurant_Review-g190454-d10803127-Reviews-3...  d10803127\n",
       "28152       id_1088     Lisbon        ['Mediterranean', 'European', 'Portuguese']   1089.0     4.0    $$ - $$$               99.0  [['See food', 'Evening meal'], ['08/24/2017', ...  /Restaurant_Review-g189158-d3574434-Reviews-Re...   d3574434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. смотрим на данные\n",
    "df = pd.read_csv('main_task.csv')\n",
    "df.info()\n",
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План предобработки данных:\n",
    "1. УКдаляю поля Restaurant_id и URL_TA (парсить пока не умею)\n",
    "2. Поле Price Range обрабатываем на основании его значений (ранжируем на уровни 1,2 и 3), пропуски заполняем 0.\n",
    "3. Поле Reviews:\n",
    "\n",
    "    3.1. Создаем 4 новых поля: два отзыва + две даты. Там, где отзывов нет - оставляем пустые строки и служебную условную дату. Аналогично поступаем с отсутствующей информацией по строкам с одним отзывом.\n",
    "    \n",
    "    3.2. Обрабатываем поля с отзывами и получаем тональность отзывов. Формируем 4 новых поля:\n",
    "    - по одному полю на оценку для каждого отзыва (1 за позитивный отзыв, -1 за негативный отзыв, 0 для смешанных или отсутствующих),\n",
    "    - одно поле на суммарную оценку по двум отзывам,\n",
    "    - одно поле для оценки динамики: 1 - если вторая оценка лучше первой (за исключением нулевых оценок), и -1, если наоборот.\n",
    "    \n",
    "   3.3. Обрабатываем даты отзывов и находим интервал между датами. Ожидаем, что date_2 > date_1. Внимательно смотрим на случаи, когда это неравенство не соблюдается. Возможно добавляем новое поле, характеризующее подобные вылеты /wrong_date/.\n",
    "    \n",
    "    \n",
    "4. Пропуски в поле Number of Reviews заполним в зависимости от обработанного поля Reviews (медианным значением, если обработанное Reviews не нулевое, или 0, если Reviews=0). Учитвая существенный разброс в поле Number of Reviews - заменим его на модификацию - возьмем логарифм.\n",
    "5. Поле Cuisine Style:\n",
    "\n",
    "   5.1. Определим все возможные стили. Возьмем стили, присутствующие в 80% ресторанов, остальные сгруппируем в одну группу.\n",
    "   \n",
    "   5.2. Сгруппируем датасет по городам и найдем:\n",
    "      - среднее количество стилей на 1 ресторан в каждом городе,\n",
    "      - самые популярные стили в каждом городе.\n",
    "      \n",
    "   5.3. На основании полученных данных заполним пропуски в исходном датасете - каждому ресторну с пропуском в поле Cuisine Style назначим характерное для его города число наиболее популярных в его городе стилей.\n",
    "   \n",
    "   5.4. Сформируем Dummy-переменные из стилей с заполненными пропусками.\n",
    "\n",
    "\n",
    "6. Поле Cities: Сформируем Dummy-переменные из городов.\n",
    "7. Дополнительную информацию точно можно спасить с сайта Tripadviser, но я пока не умею. Научусь немного позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Удаляем ненужные поля\n",
    "df.drop(['Restaurant_id','ID_TA','URL_TA',], axis=1, inplace=True)\n",
    "# я пока не умею парсить и нет времени на самостоятельное изучение. Вернусь после прохождения соответствующего модуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Обработка поля 'Price Range'\n",
    "df['Price Range'] = df['Price Range'].apply(lambda x: 0 if isnan(x) \\\n",
    "                                           else 1 if x=='$' \\\n",
    "                                           else 3 if x=='$$$$' \\\n",
    "                                           else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Обработка поля 'Reviews' (обработка ячейки занимает около 1 минуты)\n",
    "\n",
    "# Делим поле на поля с датой и с отзывами\n",
    "# 3.1. Находим даты\n",
    "pattern = re.compile('\\d\\d/\\d\\d/\\d{4}')\n",
    "df['dates']   = df['Reviews'].apply(pattern.findall)\n",
    "df['d1'] = df['dates'].apply(lambda x: pd.to_datetime(x[0]) if len(x) >0 else pd.to_datetime('2001-01-01'))\n",
    "df['d2'] = df['dates'].apply(lambda x: pd.to_datetime(x[1]) if len(x)==2 else pd.to_datetime('2001-01-01'))\n",
    "\n",
    "df['d_len']   = df['dates'].apply(len)    # Определяем количество дат и, соответственно, отзывов\n",
    "df.drop(columns=['dates'], inplace=True)\n",
    "\n",
    "\n",
    "# 3.2. Вытаскиваем отзывы\n",
    "df['Reviews'] = df['Reviews'].apply(lambda x: re.sub(pattern,'',x))  # удаляем из отзывов все даты, оставляем только текст\n",
    "df['Reviews'] = df['Reviews'].apply(simple_list)                     # приводим строку к списку, убираем лишние символы\n",
    "df['len'] = df['Reviews'].apply(lambda x: len(x) if x!=0 else x)     # определяем количество отзывов (важно сравнить len и d_len)\n",
    "\n",
    "df['Reviews'] = df.apply(lambda x: [] if x['d_len']==0 else x['Reviews'], axis=1) # заменяем пустоты на нулевой список для сопоставимости типов\n",
    "\n",
    "# Обрабатываем строки с одним отзывом, но из-за запятых маркированных как несколько отзывов\n",
    "df['Reviews'] = df.apply(lambda x: [' '.join(x['Reviews']),] if ((x['d_len']==1) and (x['len']>1)) else x['Reviews'], axis=1)\n",
    "\n",
    "# Обрабатываем строки с двумя отзывами, но из-за запятых маркированных как большее количество отзывов\n",
    "df['Reviews'] = df.apply(lambda x: [x['Reviews'][0],' '.join(x['Reviews'][1:])] if ((x['d_len']==2) and (x['len']>=2)) else x['Reviews'], axis=1)\n",
    "\n",
    "# Делим обработанное поле Reviews на два отзыва\n",
    "df['rev_1']=df['Reviews'].apply(lambda x: x[0] if len(x) >0 else '')\n",
    "df['rev_2']=df['Reviews'].apply(lambda x: x[1] if len(x)==2 else '')\n",
    "\n",
    "# Удаляем ненужные поля\n",
    "df.drop(columns=['Reviews','len'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3. Текстовый анализ и оценка отзывов (анализ занимает около 1 минуты)\n",
    "marking('rev_1','mark_1')\n",
    "marking('rev_2','mark_2')\n",
    "\n",
    "df['mark']=df['mark_1'] + df['mark_2'] # суммарная оценка по двум отзывам\n",
    "\n",
    "# Оценка динамики отзывов\n",
    "df['dynamic'] = df.apply(lambda x: (x['mark_2'] - x['mark_1'])/abs(x['mark_2'] - x['mark_1']) \\\n",
    "                                if (x['mark_2']!= x['mark_1']) and(x['mark_2']!= 0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4. Анализ дат\n",
    "df['interval'] = df['d2']-df['d1']\n",
    "df['interval'] = df['interval'].apply(lambda x: x.days if type(x)!=int else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d1'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d2'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отсечем значения до 2015г. и после марта 2018 года. Даты из 2008, 2007 годов поменяем на 2018 и 2017 года - скорее всего это ошибки \n",
    "def change_year(x_date):\n",
    "    if x_date.year==2008: x_date = datetime.date(2018, x_date.month, x_date.day)\n",
    "    if x_date.year==2007: x_date = datetime.date(2017, x_date.month, x_date.day)\n",
    "    if x_date.year< 2015: x_date = datetime.date(2001,1,1)\n",
    "    if (x_date.year>=2018) and (x_date.month>3): x_date = datetime.date(2001,1,1)\n",
    "    return x_date\n",
    "\n",
    "df['d1'] = df['d1'].apply(change_year)\n",
    "df['d2'] = df['d2'].apply(change_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hist(date,d0,d1):\n",
    "    option=(df[date]>=d0) & (df[date]<=d1)\n",
    "    df[option][date].hist(bins=100)\n",
    "    return 0\n",
    "\n",
    "d0='2017-10-01 00:00:00'\n",
    "d1='2017-12-31 00:00:00'\n",
    "\n",
    "make_hist('d1',d0,d1)\n",
    "make_hist('d2',d0,d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0='2016-10-01 00:00:00'\n",
    "d1='2016-12-31 00:00:00'\n",
    "\n",
    "make_hist('d1',d0,d1)\n",
    "make_hist('d2',d0,d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df[df['d1'].dt.year>=2015]['d1'].dt.day).size().plot.bar(rot=90, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date= 'd1'\n",
    "\n",
    "d0='2015-01-01 00:00:00'\n",
    "d1='2015-12-31 00:00:00'\n",
    "option =(df[date]>=d0) & (df[date]<=d1)\n",
    "\n",
    "df.groupby(df[option][date].dt.week).size().plot.bar(rot=90)\n",
    "df.groupby(df[option][date].dt.week).size().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Обработка поля 'Number of Reviews'\n",
    "df['Number of Reviews'].fillna(df['Number of Reviews'].median(), inplace=True)\n",
    "df['Number of Reviews'] = df['Number of Reviews'].apply(math.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Заполнение пропусков в поле 'Cuisine Style'.\n",
    "\n",
    "# 5.1. Работаем только с строками, где 'Cuisine Style' заполнено (в датасете dx).\n",
    "dx = pd.read_csv('main_task.csv')\n",
    "dx = dx[~dx['Cuisine Style'].isna()].copy()\n",
    "dx['Cuisine Style'] = dx['Cuisine Style'].apply(lambda x: [i.strip(\"'[]\") for i in x.split(', ')])\n",
    "\n",
    "# 5.2. Добавляем поле из количества различных стилей в каждом ресторане\n",
    "dx.insert(3,'num_of_cuis', dx['Cuisine Style'].apply(lambda x: len(x)))\n",
    "\n",
    "# 5.3. Разносим каждый из стилей кухонь по столбцам\n",
    "list_to_columns (dx,'Cuisine Style')\n",
    "\n",
    "# 5.4. Группируем датасет по городам и формируем для каждого города наиболее харакерные стили\n",
    "Cities = pd.DataFrame(dx.groupby('City').sum())\n",
    "Cities.drop(['Ranking','Rating','Number of Reviews'], axis=1, inplace=True)\n",
    "\n",
    "Cities.insert(1, 'num_of_rest', dx['City'].value_counts())                          # Количество ресторанов в каждом городе\n",
    "Cities.insert(2, 'cuis_per_rest', Cities['num_of_cuis']/Cities['num_of_rest'])      # Среднее количество стилей в ресторанах\n",
    "Cities['cuis_per_rest'] = Cities['cuis_per_rest'].apply(lambda x: int(round(x,0)))\n",
    "\n",
    "Cities.insert(3, 'all_uniq_cuis', Cities.apply(make_cuis_list, axis=1, args=[Cities,3]))  # Список уникальных стилей\n",
    "Cities.insert(4, 'num_of_uniq_cuis', Cities['all_uniq_cuis'].apply(lambda x: len(x)))     # Количество уникальных стилей\n",
    "Cities.insert(5, 'most_pop_cuis', Cities.apply(make_pop_cuis, axis=1, args=[Cities,5]))   # Топ самых популярных стилей\n",
    "\n",
    "# 5.5. Заполняем отсутствующие данными в боевом датасете df стилями, наиболее характерными для каждого города\n",
    "df['Cuisine Style'] = df.apply(\n",
    "    lambda x: Cities.loc[x.City]['most_pop_cuis'] \\\n",
    "    if isnan(x['Cuisine Style']) \\\n",
    "    else [i.strip(\"'[]\") for i in x['Cuisine Style'].split(', ')], axis=1)\n",
    "\n",
    "df.insert(3,'num_of_cuis', df['Cuisine Style'].apply(lambda x: len(x)))\n",
    "list_to_columns (df,'Cuisine Style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Переводим города в поля датасета\n",
    "list_to_columns (df,'City',not_a_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка поля Ranking\n",
    "df['Ranking'].hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Ranking']<1000) & (df['Ranking']>0)]['Ranking'].hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Нормализация поля Ranking\n",
    "rang_by_city = df[['City','Ranking']].groupby(by='City').max()\n",
    "df['Max_Rang'] = df.apply(lambda x: rang_by_city.loc[x.City], axis=1) \n",
    "df['Ranking']  = df['Ranking']/df['Max_Rang']\n",
    "df.drop(columns=['Max_Rang'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Разбиваем датафрейм на части, необходимые для обучения и тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "X = df.drop(['Rating','City','Cuisine Style','rev_1','rev_2','d1','d2'], axis = 1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Создаём, обучаем и тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
